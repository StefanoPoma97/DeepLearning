{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "celltoolbar": "Slideshow",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "use-gpu.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nITzLwbqW1fo",
        "colab_type": "text"
      },
      "source": [
        "# GPUs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TAYXvU6W1fs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "outputId": "8557a2b5-4892-4a86-81fe-ecd4f10e605c"
      },
      "source": [
        "!pip install mxnet-cu100"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mxnet-cu100\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/d3/e939814957c2f09ecdd22daa166898889d54e5981e356832425d514edfb6/mxnet_cu100-1.5.0-py2.py3-none-manylinux1_x86_64.whl (540.1MB)\n",
            "\u001b[K     |████████████████████████████████| 540.1MB 36kB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu100) (2.21.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu100) (1.16.5)\n",
            "Collecting graphviz<0.9.0,>=0.8.1 (from mxnet-cu100)\n",
            "  Downloading https://files.pythonhosted.org/packages/53/39/4ab213673844e0c004bed8a0781a0721a3f6bb23eb8854ee75c236428892/graphviz-0.8.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu100) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu100) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu100) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu100) (2019.6.16)\n",
            "Installing collected packages: graphviz, mxnet-cu100\n",
            "  Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "Successfully installed graphviz-0.8.4 mxnet-cu100-1.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "attributes": {
          "classes": [],
          "id": "",
          "n": "1"
        },
        "scrolled": false,
        "id": "q9yDRkLTW1f4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "d48dcee1-273c-49e4-f3ef-a8dd87e99fe3"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Sep 21 10:35:57 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 430.40       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   54C    P8    11W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXcVRZFfW1gB",
        "colab_type": "text"
      },
      "source": [
        "## Computing Devices\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GN-1xYfW1gE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b4526f19-ac58-4ecb-b1c5-103a4b6b5a97"
      },
      "source": [
        "import mxnet as mx\n",
        "from mxnet import nd\n",
        "from mxnet.gluon import nn\n",
        "\n",
        "mx.cpu(), mx.gpu(), mx.gpu(0)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(cpu(0), gpu(0), gpu(0))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzVq8YfhW1gK",
        "colab_type": "text"
      },
      "source": [
        "## NDArray and GPUs\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "attributes": {
          "classes": [],
          "id": "",
          "n": "4"
        },
        "id": "GxjooZvKW1gM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f48debba-334f-4cd4-9a53-60ecef9a9a48"
      },
      "source": [
        "x = nd.array([1, 2, 3])\n",
        "x.context"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "cpu(0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEL3WYGUW1gR",
        "colab_type": "text"
      },
      "source": [
        "### Storage on the GPU\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "attributes": {
          "classes": [],
          "id": "",
          "n": "5"
        },
        "id": "wvaf0im9W1gS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "c68d6b4a-307d-4473-9ffa-746502155910"
      },
      "source": [
        "x = nd.ones((2, 3), ctx=mx.gpu())\n",
        "x"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[[1. 1. 1.]\n",
              " [1. 1. 1.]]\n",
              "<NDArray 2x3 @gpu(0)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1pp2Dr-W1gZ",
        "colab_type": "text"
      },
      "source": [
        "Create on the second GPU:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVJi4V34W1ga",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "30806f15-4a1e-413d-aa8e-19ccc15276ec"
      },
      "source": [
        "y = nd.random.uniform(shape=(2, 3), ctx=mx.gpu(0))\n",
        "y"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[[0.6686509  0.17409194 0.3850025 ]\n",
              " [0.24678314 0.35134333 0.8404298 ]]\n",
              "<NDArray 2x3 @gpu(0)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPOLbNzHW1gg",
        "colab_type": "text"
      },
      "source": [
        "### Copy with `copyto`\n",
        "\n",
        "Inputs for an operator should be on the same device. \n",
        "\n",
        "![Copyto copies arrays to the target device](http://d2l.ai/_images/copyto.svg)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "attributes": {
          "classes": [],
          "id": "",
          "n": "7"
        },
        "id": "MuEaGhHuW1gi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "12197efe-dd01-4389-be89-8b89363d2f3a"
      },
      "source": [
        "z = x.copyto(mx.gpu(0))\n",
        "y + z"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f16aea1696ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCL9DTgWW1gm",
        "colab_type": "text"
      },
      "source": [
        "### Copy with `as_in_context`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_qKD0a6W1gn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z = x.as_in_context(mx.gpu(0))\n",
        "z"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFKu3a3CW1gs",
        "colab_type": "text"
      },
      "source": [
        "### Tiny Difference between `copyto` and  `as_in_context` "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "attributes": {
          "classes": [],
          "id": "",
          "n": "8"
        },
        "id": "gem_JzeRW1gu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Return the input if the target device is same as the source device\n",
        "y.as_in_context(mx.gpu(1)) is y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VU9ZxpQuW1gy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Always create new memory to copy the input\n",
        "y.copyto(mx.gpu()) is y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2fxunVQW1g5",
        "colab_type": "text"
      },
      "source": [
        "## Gluon and GPUs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "attributes": {
          "classes": [],
          "id": "",
          "n": "12"
        },
        "id": "t707y3NLW1g6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = nn.Sequential()\n",
        "net.add(nn.Dense(1))\n",
        "net.initialize(ctx=mx.gpu())\n",
        "\n",
        "# When the input is an NDArray on the GPU, \n",
        "# Gluon will calculate the result on the same GPU.\n",
        "print(net(x))\n",
        "net[0].weight.data()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}