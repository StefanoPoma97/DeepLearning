{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "celltoolbar": "Slideshow",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "use-gpu.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nITzLwbqW1fo",
        "colab_type": "text"
      },
      "source": [
        "# GPUs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TAYXvU6W1fs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "outputId": "7887353d-6fcf-4a39-f82c-e89d3509edab"
      },
      "source": [
        "!pip install mxnet-cu100"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mxnet-cu100 in /usr/local/lib/python3.6/dist-packages (1.5.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu100) (1.16.5)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu100) (2.21.0)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu100) (0.8.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu100) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu100) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu100) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu100) (2019.6.16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "attributes": {
          "classes": [],
          "id": "",
          "n": "1"
        },
        "scrolled": false,
        "id": "q9yDRkLTW1f4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "8295cca5-1044-45b1-b26e-5ea7a879c29b"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Sep 21 10:50:02 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 430.40       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   63C    P8    11W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXcVRZFfW1gB",
        "colab_type": "text"
      },
      "source": [
        "## Computing Devices\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GN-1xYfW1gE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "40643921-f25b-4550-bd67-1691e169595c"
      },
      "source": [
        "import mxnet as mx\n",
        "from mxnet import nd\n",
        "from mxnet.gluon import nn\n",
        "\n",
        "mx.cpu(), mx.gpu(), mx.gpu(0)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(cpu(0), gpu(0), gpu(0))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzVq8YfhW1gK",
        "colab_type": "text"
      },
      "source": [
        "## NDArray and GPUs\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "attributes": {
          "classes": [],
          "id": "",
          "n": "4"
        },
        "id": "GxjooZvKW1gM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "c725b184-5f52-41a0-8dd9-bef56ceb54c6"
      },
      "source": [
        "x = nd.array([1, 2, 3])\n",
        "x.context,x"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(cpu(0), \n",
              " [1. 2. 3.]\n",
              " <NDArray 3 @cpu(0)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEL3WYGUW1gR",
        "colab_type": "text"
      },
      "source": [
        "### Storage on the GPU\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "attributes": {
          "classes": [],
          "id": "",
          "n": "5"
        },
        "id": "wvaf0im9W1gS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "955b143a-68ae-4a51-8cfc-8f173a150e71"
      },
      "source": [
        "x = nd.ones((2, 3), ctx=mx.gpu())\n",
        "x"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[[1. 1. 1.]\n",
              " [1. 1. 1.]]\n",
              "<NDArray 2x3 @gpu(0)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1pp2Dr-W1gZ",
        "colab_type": "text"
      },
      "source": [
        "Create on the second GPU:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVJi4V34W1ga",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "00e97229-e00d-4413-b50f-78ca7ecc1356"
      },
      "source": [
        "y = nd.random.uniform(shape=(2, 3), ctx=mx.gpu(0))\n",
        "y"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[[0.6686509  0.17409194 0.3850025 ]\n",
              " [0.24678314 0.35134333 0.8404298 ]]\n",
              "<NDArray 2x3 @gpu(0)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPOLbNzHW1gg",
        "colab_type": "text"
      },
      "source": [
        "### Copy with `copyto`\n",
        "\n",
        "Inputs for an operator should be on the same device. \n",
        "\n",
        "![Copyto copies arrays to the target device](http://d2l.ai/_images/copyto.svg)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "attributes": {
          "classes": [],
          "id": "",
          "n": "7"
        },
        "id": "MuEaGhHuW1gi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "7c2706b0-77f1-48bb-e250-875125b7596a"
      },
      "source": [
        "z = x.copyto(mx.gpu(0))\n",
        "y + z"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[[1.6686509 1.1740919 1.3850025]\n",
              " [1.2467831 1.3513434 1.8404298]]\n",
              "<NDArray 2x3 @gpu(0)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCL9DTgWW1gm",
        "colab_type": "text"
      },
      "source": [
        "### Copy with `as_in_context`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_qKD0a6W1gn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "9e2e9164-e3c4-47c0-c570-ce25f28550a7"
      },
      "source": [
        "z = x.as_in_context(mx.gpu(0))\n",
        "z"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[[1. 1. 1.]\n",
              " [1. 1. 1.]]\n",
              "<NDArray 2x3 @gpu(0)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFKu3a3CW1gs",
        "colab_type": "text"
      },
      "source": [
        "### Tiny Difference between `copyto` and  `as_in_context` "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "attributes": {
          "classes": [],
          "id": "",
          "n": "8"
        },
        "id": "gem_JzeRW1gu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "12b7f503-b3f5-41c5-e151-529033ac7d8c"
      },
      "source": [
        "# Return the input if the target device is same as the source device\n",
        "y.as_in_context(mx.gpu(0)) is y"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VU9ZxpQuW1gy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "21c225ca-6f1f-4d04-96cd-14dda1374fbe"
      },
      "source": [
        "# Always create new memory to copy the input\n",
        "y.copyto(mx.gpu()) is y"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2fxunVQW1g5",
        "colab_type": "text"
      },
      "source": [
        "## Gluon and GPUs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "attributes": {
          "classes": [],
          "id": "",
          "n": "12"
        },
        "id": "t707y3NLW1g6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "cf1b08cb-df6f-444a-964d-28d200dbbb3f"
      },
      "source": [
        "net = nn.Sequential()\n",
        "net.add(nn.Dense(1))\n",
        "net.initialize(ctx=mx.gpu())\n",
        "\n",
        "# When the input is an NDArray on the GPU, \n",
        "# Gluon will calculate the result on the same GPU.\n",
        "print(net(x))\n",
        "net[0].weight.data()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[[0.04995865]\n",
            " [0.04995865]]\n",
            "<NDArray 2x1 @gpu(0)>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[[0.0068339  0.01299825 0.0301265 ]]\n",
              "<NDArray 1x3 @gpu(0)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    }
  ]
}