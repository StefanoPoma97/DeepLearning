{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Talos-04-Recover_Best_Models_from_Experiment_Log.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M66z4_m4cCb-",
        "colab_type": "text"
      },
      "source": [
        "<img src=https://raw.githubusercontent.com/autonomio/hyperio/master/logo.png>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0e4EGjmcCcH",
        "colab_type": "text"
      },
      "source": [
        "## How to recover best model from experiment log?\n",
        "Due to system error or other reason where scan_object is no longer available, it's still possible to get best model/s using nothing but the experiment log. In the below notebook you will learn exactly how.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ndPMojAibhQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##!pip install talos"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkBIR_GdvZe3",
        "colab_type": "code",
        "outputId": "12431fd7-55d2-4c87-c854-2d1a96cfd553",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 684
        }
      },
      "source": [
        "!pip install git+https://github.com/autonomio/talos"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/autonomio/talos\n",
            "  Cloning https://github.com/autonomio/talos to /tmp/pip-req-build-4w0r5zd3\n",
            "  Running command git clone -q https://github.com/autonomio/talos /tmp/pip-req-build-4w0r5zd3\n",
            "Requirement already satisfied (use --upgrade to upgrade): talos==0.6.4 from git+https://github.com/autonomio/talos in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: wrangle in /usr/local/lib/python3.6/dist-packages (from talos==0.6.4) (0.6.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from talos==0.6.4) (1.17.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from talos==0.6.4) (0.25.2)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from talos==0.6.4) (2.2.5)\n",
            "Requirement already satisfied: astetik in /usr/local/lib/python3.6/dist-packages (from talos==0.6.4) (1.9.9)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from talos==0.6.4) (0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from talos==0.6.4) (4.28.1)\n",
            "Requirement already satisfied: chances in /usr/local/lib/python3.6/dist-packages (from talos==0.6.4) (0.1.9)\n",
            "Requirement already satisfied: kerasplotlib in /usr/local/lib/python3.6/dist-packages (from talos==0.6.4) (0.1.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from talos==0.6.4) (2.21.0)\n",
            "Requirement already satisfied: scipy==1.2 in /usr/local/lib/python3.6/dist-packages (from wrangle->talos==0.6.4) (1.2.0)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.6/dist-packages (from wrangle->talos==0.6.4) (0.10.1)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->talos==0.6.4) (2.6.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->talos==0.6.4) (2018.9)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->talos==0.6.4) (2.8.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->talos==0.6.4) (1.12.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->talos==0.6.4) (3.13)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras->talos==0.6.4) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras->talos==0.6.4) (1.0.8)\n",
            "Requirement already satisfied: geonamescache in /usr/local/lib/python3.6/dist-packages (from astetik->talos==0.6.4) (1.1.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->talos==0.6.4) (0.21.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->talos==0.6.4) (2019.9.11)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->talos==0.6.4) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->talos==0.6.4) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->talos==0.6.4) (3.0.4)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from statsmodels->wrangle->talos==0.6.4) (0.5.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn->talos==0.6.4) (0.14.0)\n",
            "Building wheels for collected packages: talos\n",
            "  Building wheel for talos (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for talos: filename=talos-0.6.4-cp36-none-any.whl size=53460 sha256=b5f5f0b6786ce42486225bf9109effae828b6fd2056576c069b835922b856e43\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-vw9ekc_0/wheels/20/f1/9a/63a4168fd779c183fcc5a8ebe6aa34f1f9bc33eaa558e5461b\n",
            "Successfully built talos\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aU82jEJYrom6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "keras.__version__\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UW_Zg7ZrcCcN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.insert(0, './talos/')\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0, './wrangle/')\n",
        "\n",
        "import talos\n",
        "import wrangle\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezpQUqIzcCcg",
        "colab_type": "text"
      },
      "source": [
        "First we'll have to perform the `Scan()` experiment to produce the experiment log. Because the experiment log is stored on local machine, interrupted `Scan()` or other reason will not affect its availability. The experiment log is updated after each permutation; it contains an up-to-date record of the experiment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9jijNR-cCcj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the data\n",
        "x, y = talos.templates.datasets.iris()\n",
        "x_train, y_train, x_val, y_val = wrangle.array_split(x, y, .3)\n",
        "\n",
        "# set the parameter space boundary\n",
        "p = {'activation':['relu', 'elu'],\n",
        "     'optimizer': ['Nadam', 'Adam'],\n",
        "     'losses': ['logcosh'],\n",
        "     'shapes': ['brick'],\n",
        "     'first_neuron': [16, 32, 64, 128],\n",
        "     'hidden_layers':[0, 1, 2, 3],\n",
        "     'dropout': [.2, .3, .4],\n",
        "     'batch_size': [20, 30, 40, 50],\n",
        "     'epochs': [10]}\n",
        "\n",
        "# define the input model\n",
        "def iris_model(x_train, y_train, x_val, y_val, params):\n",
        "    print(\"\\nParams:\",params)\n",
        "    model = Sequential()\n",
        "    model.add(Dense(params['first_neuron'], input_dim=4, activation=params['activation']))\n",
        "\n",
        "    talos.utils.hidden_layers(model, params, 3)\n",
        "\n",
        "    model.add(Dense(3, activation='softmax'))\n",
        "    model.compile(optimizer=params['optimizer'], loss=params['losses'], metrics=['acc'])\n",
        "\n",
        "    #out = model.fit(x_train, y_train, callbacks=[talos.utils.ExperimentLogCallback('minimal_iris', params)],\n",
        "    #                 batch_size=params['batch_size'],\n",
        "    #                 epochs=params['epochs'],\n",
        "    #                 validation_data=[x_val, y_val],\n",
        "    #                 verbose=0)\n",
        "    out = model.fit(x_train, y_train, \n",
        "                     batch_size=params['batch_size'],\n",
        "                     epochs=params['epochs'],\n",
        "                     validation_data=[x_val, y_val],\n",
        "                     verbose=0)\n",
        "\n",
        "    return out, model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEsDMLvHqlAf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0855c6e7-4756-4d9c-c8f0-4f418cf5e81d"
      },
      "source": [
        "# start the experiment\n",
        "scan_object = talos.Scan(x=x_train,\n",
        "                         y=y_train,\n",
        "                         x_val=x_val,\n",
        "                         y_val=y_val,\n",
        "                         model=iris_model,\n",
        "                         experiment_name='reactivate',\n",
        "                         params=p,\n",
        "                         round_limit=10)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Params: {'activation': 'relu', 'batch_size': 40, 'dropout': 0.2, 'epochs': 10, 'first_neuron': 32, 'hidden_layers': 3, 'losses': 'logcosh', 'optimizer': 'Adam', 'shapes': 'brick'}\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1702: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:107: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 1/10 [00:02<00:19,  2.16s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Params: {'activation': 'relu', 'batch_size': 30, 'dropout': 0.4, 'epochs': 10, 'first_neuron': 16, 'hidden_layers': 3, 'losses': 'logcosh', 'optimizer': 'Adam', 'shapes': 'brick'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 2/10 [00:03<00:15,  1.95s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Params: {'activation': 'elu', 'batch_size': 40, 'dropout': 0.3, 'epochs': 10, 'first_neuron': 16, 'hidden_layers': 0, 'losses': 'logcosh', 'optimizer': 'Adam', 'shapes': 'brick'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 3/10 [00:04<00:11,  1.61s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Params: {'activation': 'relu', 'batch_size': 50, 'dropout': 0.4, 'epochs': 10, 'first_neuron': 16, 'hidden_layers': 3, 'losses': 'logcosh', 'optimizer': 'Nadam', 'shapes': 'brick'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 4/10 [00:05<00:09,  1.58s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Params: {'activation': 'relu', 'batch_size': 30, 'dropout': 0.2, 'epochs': 10, 'first_neuron': 16, 'hidden_layers': 1, 'losses': 'logcosh', 'optimizer': 'Nadam', 'shapes': 'brick'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 5/10 [00:07<00:07,  1.45s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Params: {'activation': 'relu', 'batch_size': 40, 'dropout': 0.4, 'epochs': 10, 'first_neuron': 128, 'hidden_layers': 0, 'losses': 'logcosh', 'optimizer': 'Nadam', 'shapes': 'brick'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 6/10 [00:07<00:05,  1.27s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Params: {'activation': 'relu', 'batch_size': 20, 'dropout': 0.3, 'epochs': 10, 'first_neuron': 16, 'hidden_layers': 2, 'losses': 'logcosh', 'optimizer': 'Nadam', 'shapes': 'brick'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 7/10 [00:09<00:04,  1.35s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Params: {'activation': 'relu', 'batch_size': 30, 'dropout': 0.2, 'epochs': 10, 'first_neuron': 128, 'hidden_layers': 0, 'losses': 'logcosh', 'optimizer': 'Nadam', 'shapes': 'brick'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 8/10 [00:10<00:02,  1.21s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Params: {'activation': 'relu', 'batch_size': 50, 'dropout': 0.4, 'epochs': 10, 'first_neuron': 32, 'hidden_layers': 0, 'losses': 'logcosh', 'optimizer': 'Adam', 'shapes': 'brick'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 90%|█████████ | 9/10 [00:11<00:01,  1.09s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Params: {'activation': 'elu', 'batch_size': 30, 'dropout': 0.4, 'epochs': 10, 'first_neuron': 128, 'hidden_layers': 2, 'losses': 'logcosh', 'optimizer': 'Nadam', 'shapes': 'brick'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r100%|██████████| 10/10 [00:12<00:00,  1.19s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3K9f8LjlcCcw",
        "colab_type": "text"
      },
      "source": [
        "Now we can assume the case where we no longer have access to the `scan_object`. In this `Scan(...experiment_name...)` was set to \"reactivate\" so we'll find a folder with that name in the present working directory. Next we have to find out what is the name of the experiment log."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96Emjpp_cCc0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "2a0c82a6-c506-4411-84bc-62a7e38d3cfb"
      },
      "source": [
        "# get the name of the experiment log\n",
        "!ls -lhtr reactivate"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 8.0K\n",
            "-rw-r--r-- 1 root root    0 Oct 26 10:09 102619100917.csv\n",
            "-rw-r--r-- 1 root root    0 Oct 26 10:11 102619101134.csv\n",
            "-rw-r--r-- 1 root root    0 Oct 26 10:12 102619101222.csv\n",
            "-rw-r--r-- 1 root root    0 Oct 26 10:44 102619104409.csv\n",
            "-rw-r--r-- 1 root root    0 Oct 26 10:44 102619104429.csv\n",
            "-rw-r--r-- 1 root root 1.4K Oct 26 11:00 102619105948.csv\n",
            "-rw-r--r-- 1 root root 1.3K Oct 26 11:06 102619110642.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZlztHC8cCc_",
        "colab_type": "text"
      },
      "source": [
        "In this case it will be the most recent one so let's go ahead and recover the best models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFx295HqcCdD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "outputId": "9aef6d1a-d8d8-4fa4-e5b6-3cbc87dd7713"
      },
      "source": [
        "from talos.utils.recover_best_model import recover_best_model\n",
        "results, models = recover_best_model(x_train=x_train,\n",
        "                                     y_train=y_train,\n",
        "                                     x_val=x_val,\n",
        "                                     y_val=y_val,\n",
        "                                     experiment_log='reactivate/102619110642.csv',\n",
        "                                     input_model=iris_model,\n",
        "                                     n_models=10,\n",
        "                                     task='multi_label')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Params: {'round_epochs': 10, 'val_loss': 0.04402541990081469, 'loss': 0.05175705573388508, 'acc': 0.8095238038471767, 'activation': 'relu', 'batch_size': 30, 'dropout': 0.2, 'epochs': 10, 'first_neuron': 128, 'hidden_layers': 0, 'losses': 'logcosh', 'optimizer': 'Nadam', 'shapes': 'brick'}\n",
            "\n",
            "Params: {'round_epochs': 10, 'val_loss': 0.009391499993701776, 'loss': 0.055485859513282776, 'acc': 0.7523809586252485, 'activation': 'elu', 'batch_size': 30, 'dropout': 0.4, 'epochs': 10, 'first_neuron': 128, 'hidden_layers': 2, 'losses': 'logcosh', 'optimizer': 'Nadam', 'shapes': 'brick'}\n",
            "\n",
            "Params: {'round_epochs': 10, 'val_loss': 0.07680413126945496, 'loss': 0.09249024944646017, 'acc': 0.5142857205300104, 'activation': 'relu', 'batch_size': 50, 'dropout': 0.4, 'epochs': 10, 'first_neuron': 16, 'hidden_layers': 3, 'losses': 'logcosh', 'optimizer': 'Nadam', 'shapes': 'brick'}\n",
            "\n",
            "Params: {'round_epochs': 10, 'val_loss': 0.05940975662734774, 'loss': 0.06377470138527097, 'acc': 0.6666666581517174, 'activation': 'relu', 'batch_size': 40, 'dropout': 0.4, 'epochs': 10, 'first_neuron': 128, 'hidden_layers': 0, 'losses': 'logcosh', 'optimizer': 'Nadam', 'shapes': 'brick'}\n",
            "\n",
            "Params: {'round_epochs': 10, 'val_loss': 0.06252893060445787, 'loss': 0.07863699893156688, 'acc': 0.6000000046832221, 'activation': 'relu', 'batch_size': 20, 'dropout': 0.3, 'epochs': 10, 'first_neuron': 16, 'hidden_layers': 2, 'losses': 'logcosh', 'optimizer': 'Nadam', 'shapes': 'brick'}\n",
            "\n",
            "Params: {'round_epochs': 10, 'val_loss': 0.09357728312412897, 'loss': 0.09447843155690602, 'acc': 0.4857142908232553, 'activation': 'relu', 'batch_size': 30, 'dropout': 0.2, 'epochs': 10, 'first_neuron': 16, 'hidden_layers': 1, 'losses': 'logcosh', 'optimizer': 'Nadam', 'shapes': 'brick'}\n",
            "\n",
            "Params: {'round_epochs': 10, 'val_loss': 0.09186607516474192, 'loss': 0.09092044440053758, 'acc': 0.5619047567957923, 'activation': 'relu', 'batch_size': 40, 'dropout': 0.2, 'epochs': 10, 'first_neuron': 32, 'hidden_layers': 3, 'losses': 'logcosh', 'optimizer': 'Adam', 'shapes': 'brick'}\n",
            "\n",
            "Params: {'round_epochs': 10, 'val_loss': 0.11284263845947055, 'loss': 0.11315545120409555, 'acc': 0.33333333475249155, 'activation': 'elu', 'batch_size': 40, 'dropout': 0.3, 'epochs': 10, 'first_neuron': 16, 'hidden_layers': 0, 'losses': 'logcosh', 'optimizer': 'Adam', 'shapes': 'brick'}\n",
            "\n",
            "Params: {'round_epochs': 10, 'val_loss': 0.1008027618130048, 'loss': 0.10601426448140826, 'acc': 0.38095238804817205, 'activation': 'relu', 'batch_size': 30, 'dropout': 0.4, 'epochs': 10, 'first_neuron': 16, 'hidden_layers': 3, 'losses': 'logcosh', 'optimizer': 'Adam', 'shapes': 'brick'}\n",
            "\n",
            "Params: {'round_epochs': 10, 'val_loss': 0.15920773148536682, 'loss': 0.16988735184783027, 'acc': 0.33333333688122885, 'activation': 'relu', 'batch_size': 50, 'dropout': 0.4, 'epochs': 10, 'first_neuron': 32, 'hidden_layers': 0, 'losses': 'logcosh', 'optimizer': 'Adam', 'shapes': 'brick'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wbhkaj-cCdP",
        "colab_type": "text"
      },
      "source": [
        "Now we can access the cross-validation results:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYPYOfyncCdR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "7a669b32-0895-4345-dd4a-b5d43ea5d779"
      },
      "source": [
        "results"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>round_epochs</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_acc</th>\n",
              "      <th>loss</th>\n",
              "      <th>acc</th>\n",
              "      <th>activation</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>dropout</th>\n",
              "      <th>epochs</th>\n",
              "      <th>first_neuron</th>\n",
              "      <th>hidden_layers</th>\n",
              "      <th>losses</th>\n",
              "      <th>optimizer</th>\n",
              "      <th>shapes</th>\n",
              "      <th>crossval_mean_f1score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>10</td>\n",
              "      <td>0.032835</td>\n",
              "      <td>0.955556</td>\n",
              "      <td>0.050778</td>\n",
              "      <td>0.761905</td>\n",
              "      <td>elu</td>\n",
              "      <td>20</td>\n",
              "      <td>0.3</td>\n",
              "      <td>10</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "      <td>logcosh</td>\n",
              "      <td>Nadam</td>\n",
              "      <td>brick</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10</td>\n",
              "      <td>0.026673</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>0.055596</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>elu</td>\n",
              "      <td>50</td>\n",
              "      <td>0.3</td>\n",
              "      <td>10</td>\n",
              "      <td>64</td>\n",
              "      <td>3</td>\n",
              "      <td>logcosh</td>\n",
              "      <td>Nadam</td>\n",
              "      <td>brick</td>\n",
              "      <td>0.565873</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>10</td>\n",
              "      <td>0.017480</td>\n",
              "      <td>0.911111</td>\n",
              "      <td>0.062210</td>\n",
              "      <td>0.752381</td>\n",
              "      <td>elu</td>\n",
              "      <td>40</td>\n",
              "      <td>0.2</td>\n",
              "      <td>10</td>\n",
              "      <td>128</td>\n",
              "      <td>2</td>\n",
              "      <td>logcosh</td>\n",
              "      <td>Nadam</td>\n",
              "      <td>brick</td>\n",
              "      <td>0.682540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10</td>\n",
              "      <td>0.037527</td>\n",
              "      <td>0.822222</td>\n",
              "      <td>0.050368</td>\n",
              "      <td>0.761905</td>\n",
              "      <td>relu</td>\n",
              "      <td>20</td>\n",
              "      <td>0.3</td>\n",
              "      <td>10</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "      <td>logcosh</td>\n",
              "      <td>Nadam</td>\n",
              "      <td>brick</td>\n",
              "      <td>0.933333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>0.069507</td>\n",
              "      <td>0.644444</td>\n",
              "      <td>0.077258</td>\n",
              "      <td>0.628571</td>\n",
              "      <td>relu</td>\n",
              "      <td>50</td>\n",
              "      <td>0.3</td>\n",
              "      <td>10</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "      <td>logcosh</td>\n",
              "      <td>Nadam</td>\n",
              "      <td>brick</td>\n",
              "      <td>0.533333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   round_epochs  val_loss   val_acc  ...  optimizer  shapes crossval_mean_f1score\n",
              "8            10  0.032835  0.955556  ...      Nadam   brick              1.000000\n",
              "2            10  0.026673  0.933333  ...      Nadam   brick              0.565873\n",
              "5            10  0.017480  0.911111  ...      Nadam   brick              0.682540\n",
              "4            10  0.037527  0.822222  ...      Nadam   brick              0.933333\n",
              "9            10  0.069507  0.644444  ...      Nadam   brick              0.533333\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_qL8diJcCdj",
        "colab_type": "text"
      },
      "source": [
        "We can also access the models and make predictions with them:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2u96gA9cCdn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 826
        },
        "outputId": "c7526a48-b0ab-42d5-a080-2c66ba8fb45d"
      },
      "source": [
        "models[0].predict(x_val)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.09669615, 0.6342103 , 0.2690936 ],\n",
              "       [0.14897366, 0.58802134, 0.26300502],\n",
              "       [0.94987273, 0.04401869, 0.00610859],\n",
              "       [0.13425532, 0.588117  , 0.27762768],\n",
              "       [0.055487  , 0.5218198 , 0.42269325],\n",
              "       [0.9578523 , 0.03717314, 0.00497459],\n",
              "       [0.01160751, 0.29222035, 0.6961721 ],\n",
              "       [0.01371114, 0.40328825, 0.5830006 ],\n",
              "       [0.9155302 , 0.07383644, 0.01063335],\n",
              "       [0.12754872, 0.6049956 , 0.26745564],\n",
              "       [0.02553807, 0.4123017 , 0.56216025],\n",
              "       [0.01160751, 0.29222035, 0.6961721 ],\n",
              "       [0.9475036 , 0.04604736, 0.00644898],\n",
              "       [0.00952294, 0.25774398, 0.7327331 ],\n",
              "       [0.9716771 , 0.02509327, 0.0032296 ],\n",
              "       [0.9535259 , 0.04067867, 0.00579546],\n",
              "       [0.94050807, 0.05207507, 0.00741676],\n",
              "       [0.01492557, 0.3651738 , 0.61990064],\n",
              "       [0.00907612, 0.3162972 , 0.6746267 ],\n",
              "       [0.01725133, 0.3527963 , 0.62995243],\n",
              "       [0.97003347, 0.0263434 , 0.00362308],\n",
              "       [0.09504172, 0.56243193, 0.34252638],\n",
              "       [0.95345765, 0.04039484, 0.0061475 ],\n",
              "       [0.92549664, 0.06439655, 0.01010676],\n",
              "       [0.94287956, 0.04974216, 0.0073783 ],\n",
              "       [0.10954163, 0.5847754 , 0.30568293],\n",
              "       [0.91675156, 0.07223283, 0.01101559],\n",
              "       [0.94150984, 0.05132849, 0.00716164],\n",
              "       [0.95611805, 0.0384796 , 0.00540235],\n",
              "       [0.1182032 , 0.5776119 , 0.30418485],\n",
              "       [0.06045303, 0.5937178 , 0.3458291 ],\n",
              "       [0.03590152, 0.505433  , 0.45866543],\n",
              "       [0.00659042, 0.2537582 , 0.7396514 ],\n",
              "       [0.02241052, 0.40513232, 0.5724572 ],\n",
              "       [0.9426046 , 0.05024016, 0.00715516],\n",
              "       [0.29159513, 0.5123052 , 0.19609974],\n",
              "       [0.0109561 , 0.2899782 , 0.6990657 ],\n",
              "       [0.9608201 , 0.03444177, 0.00473814],\n",
              "       [0.04770751, 0.4771931 , 0.47509938],\n",
              "       [0.97220516, 0.02424146, 0.00355337],\n",
              "       [0.1890651 , 0.5609294 , 0.25000545],\n",
              "       [0.01713232, 0.37063995, 0.6122277 ],\n",
              "       [0.11006001, 0.6117092 , 0.2782308 ],\n",
              "       [0.93949723, 0.05284866, 0.00765417],\n",
              "       [0.10486165, 0.56004626, 0.33509204]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    }
  ]
}